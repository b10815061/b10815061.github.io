<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN" "http://www.w3.org/TR/REC-html40/loose.dtd"> <html> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <style>.zoom-overlay{position:fixed;top:50%;left:50%;transform:translate(-50%,-50%);width:80%;height:80%;background:rgba(0,0,0,0);z-index:1000;display:flex;justify-content:center;align-items:center;opacity:0;visibility:hidden;transition:opacity .3s ease,visibility .3s;pointer-events:none}.zoom-overlay img{max-width:100%;max-height:100%;object-fit:contain;transform:scale(0.9);transition:transform .3s ease}.zoom-container:hover+.zoom-overlay,.zoom-overlay:hover{opacity:1;visibility:visible}.zoom-container:hover+.zoom-overlay img,.zoom-overlay:hover img{transform:scale(1)}</style> <script>document.addEventListener("DOMContentLoaded",function(){function e(){document.querySelectorAll(".img-fluid:not(.zoom-ready)").forEach(e=>{e.classList.add("zoom-ready");const t=document.createElement("div");t.style.position="relative";const n=document.createElement("div");n.className="zoom-container";const o=document.createElement("div");o.className="zoom-overlay";const d=document.createElement("img");d.src=e.src,o.appendChild(d),e.parentNode.insertBefore(t,e),n.appendChild(e),t.appendChild(n),t.appendChild(o)})}e(),new MutationObserver(function(t){t.forEach(function(t){t.addedNodes.length&&e()})}).observe(document.body,{childList:!0,subtree:!0})});</script> </head> <body> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/teachings/BERT/TA-480.webp 480w,/assets/img/teachings/BERT/TA-800.webp 800w,/assets/img/teachings/BERT/TA-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/teachings/BERT/TA.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="TAs" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> This lab is conducted with Feiyueh, during our time in Institute of Information Science, Academia Sinica. The target audience are doctors in the phd-level class at Chung Guan University. </div> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/teachings/BERT/Overview-480.webp 480w,/assets/img/teachings/BERT/Overview-800.webp 800w,/assets/img/teachings/BERT/Overview-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/teachings/BERT/Overview.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="overview" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> The overview of the BERT pipeline. When a user query gets in, model retrieves the most relevant document in the database. Then a LLM is employed to summarize the result and return the answer. In this lab, we will use LangChain as our external DB. Llama3, served with ollama, as our LLM. </div> <p>A comparison of traditional word embeddings and BERT’s contextualized embeddings. The left image illustrates basic word embeddings where each word has a fixed vector representation in a continuous space - similar words like ‘dog’, ‘cat’, and ‘rabbit’ cluster together, while semantically different words like ‘tree’ and ‘flower’ occupy different regions. The right image shows BERT’s (<a href="https://arxiv.org/abs/1810.04805" rel="external nofollow noopener" target="_blank">Devlin et al., 2019</a>) more sophisticated encoding approach, where each token’s representation is dynamically influenced by its context. The visualization demonstrates how BERT combines token embeddings (E_token), segment embeddings (E_A/E_B), and positional embeddings (E_0 to E_10) to create context-aware representations, enabling the model to understand the same word differently based on its usage in different contexts.</p> <div class="row justify-content-sm-center"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/teachings/BERT/Context-480.webp 480w,/assets/img/teachings/BERT/Context-800.webp 800w,/assets/img/teachings/BERT/Context-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/teachings/BERT/Context.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/teachings/BERT/BertFormat-480.webp 480w,/assets/img/teachings/BERT/BertFormat-800.webp 800w,/assets/img/teachings/BERT/BertFormat-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/teachings/BERT/BertFormat.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> </body> </html>